{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrZiPp4XWdFN"
      },
      "source": [
        "# Author: Riya Nakarmi ###<br>\n",
        "# College Project ###"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Cg6aM0lfoxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TZWuDsSvWdFP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEHU_Wv1fuKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QrWEa1pvWdFQ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W0z-oY6jWdFQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n6NmX7tsWdFQ"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OY0lRWZwXPHg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = pd.read_json(\"/content/intents.json\")"
      ],
      "metadata": {
        "id": "oqw9GEhqXEb6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from keras.models import load_model\n",
        "\n",
        "# Assuming the files are encoded using 'latin1'\n",
        "with open('/content/words.pkl', 'rb') as f:\n",
        "    words = pickle.load(f, encoding='latin1')\n",
        "\n",
        "with open('/content/classes.pkl', 'rb') as f:\n",
        "    classes = pickle.load(f, encoding='latin1')\n",
        "\n",
        "model = load_model('/content/chatbotmodel.h5')\n"
      ],
      "metadata": {
        "id": "bclvcKTnYUfV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1yWKiRSWWdFR"
      },
      "outputs": [],
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [lemmatizer.lemmatize(word)  for word in sentence_words]\n",
        "    return sentence_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TXRPqwfwWdFR"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(sentence):\n",
        "    sentence_words= clean_up_sentence(sentence)\n",
        "    bag = [0] * len(words)\n",
        "    for w in sentence_words:\n",
        "        for i, word in enumerate(words):\n",
        "            if word == w:\n",
        "                bag[i] = 1\n",
        "    return np.array(bag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hLzcM-gXWdFR"
      },
      "outputs": [],
      "source": [
        "def predict_class(sentence):\n",
        "    bow = bag_of_words(sentence)\n",
        "    res = model.predict(np.array([bow]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "    results.sort(key=lambda  x:x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
        "    return return_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yc8l5og7WdFR"
      },
      "outputs": [],
      "source": [
        "def get_response(intents_list,intents_json):\n",
        "    tag= intents_list[0]['intent']\n",
        "    list_of_intents =intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if i['tag'] == tag:\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Download the punkt tokenizer\n",
        "nltk.download('wordnet')  # Download the wordnet resource\n",
        "\n",
        "# Rest of your code\n",
        "print(\"|============= Welcome to College Equiry Chatbot System! =============|\")\n",
        "print(\"|============================== Feel Free ============================|\")\n",
        "print(\"|================================== To ===============================|\")\n",
        "print(\"|=============== Ask your any query about our college ================|\")\n",
        "\n",
        "while True:\n",
        "    message = input(\"| You: \")\n",
        "    if message == \"bye\" or message == \"Goodbye\":\n",
        "        ints = predict_class(message)\n",
        "        res = get_response(ints, intents)\n",
        "        print(\"| Bot:\", res)\n",
        "        print(\"|===================== The Program End here! =====================|\")\n",
        "        exit()\n",
        "    else:\n",
        "        ints = predict_class(message)\n",
        "        res = get_response(ints, intents)\n",
        "        print(\"| Bot:\", res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHzWWSL8ZNfx",
        "outputId": "593c5710-8c08-4081-9bea-0612ee9fbbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|============= Welcome to College Equiry Chatbot System! =============|\n",
            "|============================== Feel Free ============================|\n",
            "|================================== To ===============================|\n",
            "|=============== Ask your any query about our college ================|\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "| Bot: What can I do for you?\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "| Bot: What can I do for you?\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "| Bot: There are assignments which carry more weight than your written exams. The assignments have deadlines which you should not exceed if you want to get better marks.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "| Bot: There are two semesters in a year.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}